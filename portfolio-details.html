<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>MNIST Data-Set</title>
  <meta name="Description" content="Analysis of the MNIST data set using a variational Autoencoder" >
  <meta name="Machine Learning" content="Variational Autoencoder" >

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/favicon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/profile-img2.jpg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Adam Paslawski</a></h1>
        <div class="social-links mt-3 ">
          <a href="linkedin.com/in/adam-paslawski-098b53162" class="linkedin"><i class="bx bxl-linkedin"></i></a>
        </div>
      </div>

      <nav class="nav-menu">
        <ul>
          <li class="active"><a href="index.html"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="index.html#about"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="index.html#resume"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="index.html#portfolio"><i class="bx bx-book-content"></i> Portfolio</a></li>
        </ul>
      </nav><!-- .nav-menu -->
      <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>
    </div>
  </header><!-- End Header -->
    <!-- ======= Hero Section ======= -->
    <section id="hero-p" class="hero-2 d-flex flex-column justify-content-center align-items-center">
      <div class="hero-container" data-aos="fade-in">
        <h1 class = "portfoli-title">Teaching a computer to Handwrite</h1>
      </div>
    </section><!-- End Hero -->

  <main id="main">
    <!-- ======= Report Begins Here======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">
        <!-- OVERVIEW -->
        <div class="portfolio-description">
          <h1 class = "col-lg-12">Overview</h1>
          <p class = "col-lg-12">
            The MNIST data set is a collection of about 70,000 28x28 pixel images of handwritten digits like the one below.
          </p>
          <div class="row" data-aos="fade-left">
            <div class="container ">
              <img class = "col-lg-12 square-img" src="assets/img/portfolio/vae/entire9.png" alt="">
            </div>
            <p class = "col-lg-12">
              The goal of the project is to use a variational autoencoder to learn a probability distribution relating the greyscale value of every pixel in the image to the identity of that digit.
            </p>
          </div>
          <div class="row" data-aos="fade-left">
            <p class = "col-lg-12">
                The techniques used are based on the paper <a href="https://arxiv.org/pdf/1312.6114.pdf">Auto-Encoding Variational Bayes </a>.
            </p>
          </div>
          <p>






          </p>
          <div class="row" data-aos="fade-left">
            <h1 class = "col-lg-12"></br><em>"What is a variational autoencoder?"</em></h1>
            <p class = "col-lg-12">A variational autoencoder has two pieces:</p>
            <ol class = "col-lg-12">
              <li><b><u>Encoder:</u> </b> Encodes the image to a high dimensional latent representation.</li>
              <li><b><u>Decoder:</u></b> Decodes a latent representation to an image.</li>
            </ol>
          </div>
        </div>


        <!-- Encoder section -->
        <div class="portfolio-description">
          <div class="row" data-aos ="fade-left">
            <h1 class = "col-lg-12">The Encoder</h1>
            <p class = "col-lg-12">The Encoder takes a 28x28 pixel image and transforms those pixels to a latent representation of that image.</p>
            <p class = "col-lg-12">In this case were going from 784 dimensions  (784 pixels) down to a multivariate gaussian.</p>
            <div class="container ">
              <img  class = "horrizontal-img col-lg-12" src="assets/img/portfolio/vae/encoder.png" alt="Encoder Network">
            </div>
            <p class = "col-lg-12">Implemented like this:</p>
            <div class="container ">
              <pre>
                <code>
def neural_net_predict(params, inputs):
"""Params is a list of (weights, bias) tuples.
  inputs is an (N x D) matrix.
  Applies batch normalization to every layer but the last."""
for W, b in params:
    outputs = np.dot(inputs, W) + b  # linear transformation
    inputs = np.tanh(outputs)           # nonlinear transformation
return outputs

def nn_predict_gaussian(params, inputs):
  #Returns means and diagonal variances
  return unpack_gaussian_params(neural_net_predict(params, inputs))


def encoder(x , rec_params):
  return(nn_predict_gaussian(rec_params,x))
                </code> 
              </pre>
            </div>
        </div>



        <!-- Decoder section -->
        <div class="portfolio-description">
          <div class="row" data-aos ="fade-left">
            <h1 class = "col-lg-12">The Decoder</h1>
            <p class = "col-lg-12">The decoder does the opposite, it takes an encoding of an image and decodes it to generate an image, it just runs it through our simple single hidden layer neural network.</p>
            <div class="container ">
              <img class = "horrizontal-img" src="assets/img/portfolio/vae/decoder.png" alt="Decoder network">
            </div>
            <p class = "col-lg-12">Implemented like this:</p>
            <div class="container ">
              <pre>
                <code>
def decoder(params,z):
  return(neural_net_predict(params,z))
                </code> 
              </pre>
            </div>
          </div>
        </div>


        <div class="portfolio-description ">
          <div class="row" data-aoe = "fade-left">
            <h1 class = " col-lg-12" >An Untrained Network</h1>
            <p class = "col-lg-12">Unless you get outrageously lucky and initialize all your network parameters right the first time the network will do something like this:</p>
            <div class="container ">
              <img class = "col-lg-12 horrizontal-img" src="assets/img/portfolio/vae/decoder-foreal.jpg" alt="Encoder Decoder network producing noise">
            </div>
            <p class = "col-lg-12">Thats because the mathematical transformations are totally random and havent learned how to deconstruct and reconstruct these images ... yet.</p>
          </div>
        </div>

        <div class="portfolio-description">
          <div class="row" data-aoe = "fade-left">
            <h1 class = "col-lg-12">Training</h1>
            <p class = "col-lg-12">Just like great athletes , variational autoencoders need lots of training.</p>
            <p class = "col-lg-12">We will do this by trying to make sure when we decode and encode an image we get close to the same thing back.</p>
            <p class="col-lg-12">Mathematically we are maximizing a lower bound estimate of the loss which is outlined in <a href="https://arxiv.org/pdf/1312.6114.pdf">the paper this is based on.</a>  Its called the ELBO and its the loss function for the back propogation algorithm used for gradient descent.</p>
            <p class="col-lg-12">Implementing this in a scalable  way:</p>
            <div class="container ">
              <pre>
                <code>
  def vae_lower_bound(gen_params, rec_params, data, rs):
    # We use a simple Monte Carlo estimate of the KL
    # divergence from the prior.
    q_means, q_log_stds = encoder(data , rec_params)
    latents = sample_diag_gaussian(q_means , q_log_stds,npr.RandomState(0))
    log_q_z = diag_gaussian_log_density(latents,q_means,q_log_stds)
    log_prior_z = log_prior(latents)
    log_p_x_given_z = log_likelihood(gen_params, data, latents)
    joint = log_prior_z + log_p_x_given_z
    elbo_estimate = np.mean(joint - log_q_z)
    return elbo_estimate
                </code>
              </pre>
            </div>
          </div>
          <p class = "col-lg-12">Now if we compare original images with the generated version below we can see:</p>
          <div class="container ">
            <img class = "horrizontal-img", src="assets/img/portfolio/vae/2by10plot.png" alt="">
          </div>
          <p class="col-lg-12">They look remarkably similar, which means our model has been trained well!</p>
        </div>
        <div class="portfolio-description ">
          <div class="row" data-aoe = "fade-left">
            <h1 class="col-lg-12">Applications</h1>
            <!-- Application 1 -->
            <h2 class = " col-lg-12" ><b> <u>  1. Getting Our Computer to Handwrite</u></b></h1>
            <p class = "col-lg-12">One application of a variational autoencoder is using it to generate unseen data.</p>
            <div class="container ">
              <img class = "square-img" src="assets/img/portfolio/vae/entire9-generated.png" alt="Handwritten number 9">
            </div>
            <p class = "col-lg-12">This number 9 was generated from the multivariate gaussian distribution for the number 9 that the model learned.</p>
            <!-- Application 2 -->
            <h2 class = " col-lg-12" > <b> <u>2. Interpolating Between Handwritten Numbers</u></b></h1>
            <p class = "col-lg-12">Since the digits "live" in  a latent space so we can interpolate between numbers and see how the model is understanding how digits are related.</p>
            <div class="container ">
              <img class = "horrizontal-img" src="assets/img/portfolio/vae/interpolation.png" alt="Handwritten number 9">
            </div>
            <!-- Application 3 -->
            <h2 class = " col-lg-12" ><b> <u>3. Predicting the bottom half of the image given the top </u></b> </h1>
            <p class = "col-lg-12">Another application is generating the bottom half of the image given the top by training the autoencoder using only the top half of the image but computing the loss based on comparing the entire image.</p>
          </div>
        </div>
      </div>
    </section>
    <!-- End Report -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">

  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>